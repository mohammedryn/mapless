<div align="center">

# ğŸŒ² Mapless DRL Forest Navigation

**Autonomous collision-free robot navigation through unstructured environments using Deep Reinforcement Learning â€” no maps required.**

[![ROS2 Humble](https://img.shields.io/badge/ROS2-Humble-blue?logo=ros&logoColor=white)](https://docs.ros.org/en/humble/)
[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-yellow?logo=python&logoColor=white)](https://www.python.org/)
[![PPO](https://img.shields.io/badge/Algorithm-PPO-green)](https://stable-baselines3.readthedocs.io/)
[![Stable Baselines 3](https://img.shields.io/badge/Stable--Baselines3-2.x-orange)](https://stable-baselines3.readthedocs.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-red.svg)](https://opensource.org/licenses/MIT)

</div>

---

## ğŸ§  What Is This?

Most robots navigate using a **pre-built map** (SLAM). If a chair moves, they get confused.

This project takes a fundamentally different approach: a ground robot that **learns to navigate** by interacting with its environment â€” like an animal moving through a forest. Using **Proximal Policy Optimization (PPO)**, the robot's neural network learns to read raw 360Â° Lidar data and output velocity commands that avoid obstacles and reach a goal.

**No map. No hand-coded rules. Just a sensor, a goal, and a trained brain.**

### Key Innovations

| Innovation | What It Means |
| :--- | :--- |
| **Mapless Navigation** | Zero dependency on SLAM or prior maps. Reactive to dynamic changes in real-time. |
| **Encoder-free Odometry** | No wheel encoders on the chassis. Pose is estimated entirely from Lidar scan-matching via `rf2o`. |
| **End-to-End Learning** | Raw sensor input â†’ continuous velocity output. No hand-crafted waypoints or rules. |
| **Edge Deploy** | Full inference stack runs on the Jetson Orin Nano at 10 Hz. |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        REAL ROBOT STACK                         â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    /scan    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Slamtec     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   rf2o_laser_odometry          â”‚â”‚
â”‚  â”‚  Lidar C1M1  â”‚            â”‚   (Scan Matching â†’ /odom)      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                         â”‚ /odom                 â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    /scan   â”‚   NavigationNode               â”‚â”‚
â”‚  â”‚  Slamtec     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   (Loads PPO Model)            â”‚â”‚
â”‚  â”‚  Lidar C1M1  â”‚            â”‚   obs = [scan(360) + dist + Î¸] â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   action = model.predict(obs)  â”‚â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                         â”‚ /cmd_vel              â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚                              â”‚   SabertoothDriver             â”‚â”‚
â”‚                              â”‚   (Packet Serial â†’ motors)     â”‚â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                         â”‚                       â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚                              â”‚   JGB37 Motors (x4)            â”‚â”‚
â”‚                              â”‚   via Sabertooth 2x32          â”‚â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Observation Space (362-dimensional)

| Index | Value | Range |
| :--- | :--- | :--- |
| `[0â€¦359]` | Normalized Lidar ranges (360Â°) | `[0, 1]` |
| `[360]` | Normalized goal distance | `[0, 1]` |
| `[361]` | Normalized angle to goal | `[-1, 1]` |

### Action Space (2-dimensional, continuous)

| Index | Meaning | Maps To |
| :--- | :--- | :--- |
| `[0]` | Linear velocity | `[0, 0.26] m/s` |
| `[1]` | Angular velocity | `[-1.82, 1.82] rad/s` |

### Reward Function

```python
if min_lidar_range < 0.20m:
    reward = -100   # Collision
elif distance_to_goal < 0.5m:
    reward = +100   # Goal Reached!
else:
    reward = (progress_toward_goal Ã— 10) - 0.1  # Progress - time penalty
```

---

## ğŸ”§ Hardware

| Component | Specification / Details | Role |
| :--- | :--- | :--- |
| **Compute** | Raspberry Pi 5 (8GB) | Runs ROS2, handles Lidar Odometry, and executes the PPO inference. |
| **Lidar** | Slamtec Lidar C1M1 R2 | Primary sensor for obstacle detection and encoder-less odometry. |
| **Motor Drivers**| 2x BTS7960 43A Drivers | High-current PWM drivers for the left and right motor banks. |
| **Motors** | 4x JGB37 DC Motors | High-torque propulsion (No encoders needed). |
| **Vision** | Raspberry Pi HQ Camera | (Optional) Future integration for vision-language models. |
| **Power** | 12V LiPo Battery | Dedicated power for motors and buck-converter for Pi 5. |
Odometry is derived entirely from Lidar scan-matching using `rf2o_laser_odometry`.

---

## ğŸ“ Project Structure

```
mapless/
â”œâ”€â”€ src/                        # Core ROS2 Python nodes
â”‚   â”œâ”€â”€ forest_env.py           # Gymnasium environment wrapper (training)
â”‚   â”œâ”€â”€ train_ppo.py            # PPO training script
â”‚   â”œâ”€â”€ navigation_node.py      # Deployment inference node (10 Hz)
â”‚   â””â”€â”€ sabertooth_driver.py    # Custom Packet Serial motor driver
â”‚
â”œâ”€â”€ launch/                     # Launch files
â”‚   â”œâ”€â”€ real_robot.launch.py    # Full hardware stack (Lidar â†’ Odom â†’ AI â†’ Motors)
â”‚   â”œâ”€â”€ forest_sim.launch.xml   # Simulation-only (Gazebo)
â”‚   â”œâ”€â”€ forest_nav.launch.xml   # Navigation in sim with trained model
â”‚   â””â”€â”€ deploy.launch.xml       # Lightweight deploy launcher
â”‚
â”œâ”€â”€ config/                     # Configuration YAML files
â”‚   â”œâ”€â”€ training.yaml           # PPO hyperparameters
â”‚   â””â”€â”€ rover.yaml              # Robot physical parameters
â”‚
â”œâ”€â”€ models/                     # Trained neural network models
â”‚   â”œâ”€â”€ ppo_forest_nav.zip      # Latest trained model
â”‚   â””â”€â”€ checkpoints/            # Training checkpoints
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ SETUP.md                # Full Jetson setup guide
â”‚   â”œâ”€â”€ CONNECTIONS.md          # Hardware wiring & DIP switch guide
â”‚   â”œâ”€â”€ PROGRESS.md             # Project progress & technical deep-dive
â”‚   â”œâ”€â”€ reference.md            # Extended project reference
â”‚   â””â”€â”€ media/                  # Images and demo videos
â”‚
â”œâ”€â”€ package.xml
â”œâ”€â”€ setup.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ install_dependencies.sh
```

---

## ğŸš€ Getting Started

### Prerequisites

- **OS**: Ubuntu 22.04 (Jammy)
- **ROS2**: Humble Hawksbill
- **Python**: 3.10+
- **GPU** *(optional for training)*: CUDA 12.4+

### 1. Clone & Install

```bash
git clone https://github.com/mohammedryn/mapless.git
cd mapless
chmod +x install_dependencies.sh
./install_dependencies.sh
sudo reboot   # Required for USB serial permissions
```

### 2. Build

```bash
cd ~/mapless
colcon build --symlink-install
source install/setup.bash
```

> **Tip:** Add `source ~/mapless/install/setup.bash` to your `~/.bashrc` to avoid typing it every session.

---

## ğŸ® Usage

### Training (Simulation)

Launch the Gazebo forest environment:
```bash
ros2 launch mapless_navigation forest_sim.launch.xml
```

Start PPO training (2 million steps by default):
```bash
ros2 run mapless_navigation train_ppo
```

Resume from a saved checkpoint:
```bash
ros2 run mapless_navigation train_ppo --continue_training
```

Monitor training with TensorBoard:
```bash
tensorboard --logdir ./ppo_forest_tensorboard
```

### Deployment (Real Robot)

> Ensure Lidar and Sabertooth are plugged in before running.

```bash
ros2 launch mapless_navigation real_robot.launch.py
```

This single command starts the full stack:
`Lidar Driver â†’ TF Publisher â†’ Lidar Odometry â†’ Motor Driver â†’ AI Navigation Node`

### Verify It's Working

In a second terminal, check odometry is flowing:
```bash
ros2 topic echo /odom
```

Send a manual test command (wheels spin for 1 second):
```bash
ros2 topic pub --once /cmd_vel geometry_msgs/msg/Twist \
  "{linear: {x: 0.1}, angular: {z: 0.0}}"
```

---

## âš™ï¸ Configuration

### Training Hyperparameters â€” [`config/training.yaml`](config/training.yaml)

| Parameter | Value | Notes |
| :--- | :--- | :--- |
| `total_timesteps` | 2,000,000 | Increase for better forest generalization |
| `learning_rate` | 0.0003 | Standard PPO starting point |
| `gamma` | 0.99 | High discount â€” robot plans long-term |
| `collision_penalty` | 100.0 | Strongly discourages hitting trees |

### Robot Parameters â€” [`config/rover.yaml`](config/rover.yaml)

| Parameter | Value |
| :--- | :--- |
| `max_linear_vel` | 0.26 m/s |
| `max_angular_vel` | 1.82 rad/s |
| `lidar_fov` | 360Â° |

---

## ğŸ”Œ Hardware Wiring

> See the full guide in [`docs/CONNECTIONS.md`](docs/CONNECTIONS.md).

**Quick Reference â€” Sabertooth DIP Switches (Packet Serial, Address 128):**

| SW1 | SW2 | SW3 | SW4 | SW5 | SW6 |
|:---:|:---:|:---:|:---:|:---:|:---:|
| OFF | OFF | ON *(LiPo)* | OFF | OFF | OFF |

---

## ğŸ› ï¸ Troubleshooting

| Symptom | Likely Cause | Fix |
| :--- | :--- | :--- |
| `Permission denied` on serial | USB group not set | Ensure `install_dependencies.sh` was run & rebooted |
| `Package not found` | Workspace not sourced | Run `source install/setup.bash` |
| `/odom` not updating | Lidar not spinning or wrong port | Check `ls /dev/ttyUSB*` and update `real_robot.launch.py` |
| Wheels spin wrong direction | Motor wires reversed | Swap M1A â†” M1B (or M2A â†” M2B) on Sabertooth |
| Robot crashes in real world | Sim-to-real gap | Tune speed scaling in `sabertooth_driver.py` |

---

## ğŸ“Š Performance

- **Estimated Success Rate**: 85â€“90% in forest environments
- **Inference Latency**: ~10 Hz on Jetson Orin Nano
- **Training Time**: ~4â€“8 hours for 2M steps (with GPU)

---

## ğŸ—ºï¸ Roadmap

- [x] Custom Gymnasium environment with ROS2 bridge
- [x] PPO agent training with Stable Baselines 3
- [x] Real robot deployment node (10 Hz inference)
- [x] Custom Sabertooth Packet Serial driver
- [x] Lidar-only odometry via `rf2o`
- [ ] Safety override layer (emergency stop on close obstacles)
- [ ] Domain randomization for improved sim-to-real transfer
- [ ] IMU-fused odometry for improved robustness
- [ ] RViz visualization launch file

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!

1. Fork the repository
2. Create your branch: `git checkout -b feature/your-feature`
3. Commit your changes: `git commit -m 'Add your feature'`
4. Push and open a Pull Request

---

## ğŸ“„ License

Distributed under the MIT License. See `LICENSE` for more information.

---

## ğŸ™ Acknowledgements

- [Stable Baselines 3](https://github.com/DLR-RM/stable-baselines3) â€” PPO implementation
- [rf2o_laser_odometry](https://github.com/MAPIRlab/rf2o_laser_odometry) â€” Lidar scan-matching odometry
- [sllidar_ros2](https://github.com/Slamtec/sllidar_ros2) â€” Slamtec Lidar ROS2 driver
- [Gymnasium](https://gymnasium.farama.org/) â€” RL environment interface

---

<div align="center">

**Built with â¤ï¸ by Mohammed Rayan**

[â­ Star this repo](https://github.com/mohammedryn/mapless) Â· [ğŸ› Report a Bug](https://github.com/mohammedryn/mapless/issues) Â· [ğŸ’¡ Request a Feature](https://github.com/mohammedryn/mapless/issues)

</div>
